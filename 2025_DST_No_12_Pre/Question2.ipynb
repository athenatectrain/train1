{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004f2d14",
   "metadata": {},
   "source": [
    "# 演習問題2\n",
    "## Cntextial Inquiry法にWord2Vecを用いる\n",
    "\n",
    "社会人講座第3回で作成したシナリオから分散表現を獲得し，スケジュール管理における不便さやストレスを探り，ITツールを活用してより効率的かつ正確に予定を管理する方法を見つける．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import MeCab\n",
    "import ipadic\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "#rcParamsに文字化けしないようにフォントの設定を行う\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形態素解析器の初期化\n",
    "tagger = MeCab.Tagger(ipadic.MECAB_ARGS)\n",
    "tagger.parse(\"\")  # MeCabの初期化（空文字列を解析することで初期化）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c286a4b",
   "metadata": {},
   "source": [
    "### ストップワードの改良"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 追加のストップワードを設定\n",
    "additionel_stopwords = [\"a\", \"いる\", \"か月\", \"する\", \"ユーザ\"]\n",
    "\n",
    "# ストップワードの読み込み\n",
    "with open(\"stop_words.txt\", encoding=\"utf-8\") as f:\n",
    "    stop_words = set(line.strip().lower() for line in f if line.strip())\n",
    "\n",
    "# ストップワードを追加\n",
    "stop_words.update(map(str.lower, additionel_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad742ea",
   "metadata": {},
   "source": [
    "### トークナイズにおける問題点\n",
    "\n",
    "辞書によってはトークナイズの際におかしな分け方をしてしまう<br>\n",
    "例：スマホ⇒[スマ, ホ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df453172",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = tagger.parse(\"メモを取る際、スマホを使う\")\n",
    "print(parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68cbe94",
   "metadata": {},
   "source": [
    "カタカナ語が連続する場合，連結するようにトークナイズする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 英数字・記号などの正規化関数\n",
    "def clean_token(surface):\n",
    "    surface = surface.lower()\n",
    "    surface = re.sub(r'[0-9０-９一二三四五六七八九十百千万億兆]+', '', surface)\n",
    "    surface = re.sub(r'[^\\wぁ-んァ-ン一-龥ー]+', '', surface)\n",
    "    return surface\n",
    "\n",
    "# トークナイズ＋カタカナ語の連結\n",
    "def tokenize_clean(text):\n",
    "    node = tagger.parseToNode(text)\n",
    "    tokens = []\n",
    "    buffer = \"\"  # カタカナ連続語用バッファ\n",
    "\n",
    "    while node:\n",
    "        surface = node.surface\n",
    "        features = node.feature.split(',')\n",
    "        pos = features[0]\n",
    "        base = features[6] if len(features) > 6 and features[6] != '*' else surface\n",
    "        norm = clean_token(base)\n",
    "\n",
    "        # カタカナだけで構成されているならバッファに追加\n",
    "        if re.fullmatch(r'[ァ-ンー]+', surface):\n",
    "            buffer += surface\n",
    "        else:\n",
    "            # カタカナバッファがあればまず吐き出す\n",
    "            if buffer:\n",
    "                if buffer.lower() not in stop_words:\n",
    "                    tokens.append(buffer.lower())\n",
    "                buffer = \"\"\n",
    "            # 通常の単語処理\n",
    "            if pos in [\"名詞\", \"動詞\", \"形容詞\"] and norm and norm not in stop_words:\n",
    "                tokens.append(norm)\n",
    "        node = node.next\n",
    "\n",
    "    # 最後にバッファを処理\n",
    "    if buffer and buffer.lower() not in stop_words:\n",
    "        tokens.append(buffer.lower())\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f37d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# スマホが[スマ, ホ]に分かれなくなる\n",
    "print(tokenize_clean(\"メモを取る際、スマホを使う\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1c83d1",
   "metadata": {},
   "source": [
    "### コーパスを読み込む\n",
    "今回は，コーパスに皆様が作成されたシナリオを使用しています．<br>\n",
    "分析の邪魔にならないように\"・\"はすべて削除しています．<br>\n",
    "シナリオに書かれていた名前の部分はすべて\"ユーザ\"に書き換えています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コーパスの読み込み\n",
    "df = pd.read_csv(\"./csv/scenario_data.csv\")\n",
    "\n",
    "# トークン化\n",
    "sentences = df[\"text\"].apply(tokenize_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3f9f5",
   "metadata": {},
   "source": [
    "### 同じ意味を持つ単語を統合\n",
    "\"pc\"と\"パソコン\"など同じ意味を持つ単語を1語に統合することで，単語空間の過剰な分散を防げる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b46a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 意味の同じ単語を1語にまとめるための変換辞書\n",
    "replace_dict = {\n",
    "    \"pc\": \"パソコン\" # \"pc\"をすべて\"パソコン\"に置き換える\n",
    "}\n",
    "\n",
    "# 統合関数により単語の並びを変えることなく目的語を変換出来る\n",
    "def batch_replace(sentences, replace_dict):\n",
    "    return [\n",
    "        [replace_dict.get(token, token) for token in sentence]\n",
    "        for sentence in sentences\n",
    "    ]\n",
    "\n",
    "# 変換辞書を適用\n",
    "sentences = batch_replace(sentences, replace_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2297fef1",
   "metadata": {},
   "source": [
    "### Word2Vecの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004bda86",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences, \n",
    "    vector_size=100, \n",
    "    window=5, \n",
    "    min_count=2, \n",
    "    sg=1,\n",
    "    seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"モデルの語彙数：{len(w2v_model.wv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71abfb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストを空白区切りにして渡す\n",
    "joined_texts = [\" \".join(tokens) for tokens in sentences]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(joined_texts)\n",
    "feature_names = vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# すべてのシナリオのTF-IDF上位単語\n",
    "for j in range(len(sentences)):\n",
    "    row = tfidf_matrix[j].toarray().flatten()\n",
    "    top_indices = row.argsort()[::-1][:5]\n",
    "    top_words = [feature_names[i] for i in top_indices if feature_names[i] in w2v_model.wv]\n",
    "\n",
    "    print(f\"シナリオ{j}番目のTF-IDF上位語:\", top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任意のシナリオのTF-IDF上位単語\n",
    "scenarioID = 0\n",
    "row = tfidf_matrix[scenarioID].toarray().flatten()\n",
    "top_indices = row.argsort()[::-1][:5]\n",
    "top_words = [feature_names[i] for i in top_indices if feature_names[i] in w2v_model.wv]\n",
    "\n",
    "print(f\"シナリオ{scenarioID}番目のTF-IDF上位語:\", top_words)\n",
    "\n",
    "# 平均ベクトルを求める\n",
    "word_vecs = [w2v_model.wv[word] for word in top_words]\n",
    "avg_vec = np.mean(word_vecs, axis=0)\n",
    "\n",
    "# 周辺語を表示\n",
    "similar_words = w2v_model.wv.similar_by_vector(avg_vec, topn=10)\n",
    "print(f\"シナリオ{scenarioID}番目の周辺語:\")\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf32cd79",
   "metadata": {},
   "source": [
    "### 意味マップの画像化\n",
    "任意の単語とその単語の類似度上位20単語からなる空間をPCAで2次元に圧縮し画像化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37102e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_map_pca(center_word, model, topn=20):\n",
    "    if center_word not in model.wv:\n",
    "        print(f\"{center_word} は語彙にありません。\")\n",
    "        return\n",
    "\n",
    "    # 類似語取得\n",
    "    similar_words = model.wv.most_similar(center_word, topn=topn)\n",
    "    words = [center_word] + [w for w, _ in similar_words]\n",
    "    vecs = np.array([model.wv[w] for w in words])\n",
    "\n",
    "    # PCAで2次元に圧縮\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    vecs_2d = pca.fit_transform(vecs)\n",
    "\n",
    "    # プロット\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, word in enumerate(words):\n",
    "        x, y = vecs_2d[i]\n",
    "        plt.scatter(x, y, color='red' if i == 0 else 'blue')\n",
    "        plt.text(x, y, word, fontsize=12)\n",
    "    plt.title(f\"PCA: '{center_word}' を中心とした意味マップ\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc12665",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word = \"スマホ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b03028",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w2v_model.wv.most_similar(target_word, topn=20))\n",
    "plot_word_map_pca(target_word, w2v_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f5613d",
   "metadata": {},
   "source": [
    "### 考察問題1 スマホを中心とした意味マップから本コーパスにおける\"スマホ\"はどのような使われ方をしているか考察してください"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dbd318",
   "metadata": {},
   "source": [
    "回答欄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a797b",
   "metadata": {},
   "source": [
    "## 課題 自分で前処理を設計して得られた結果から考察してください\n",
    "唯一の答えはないので自由に考察してください．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097ff87",
   "metadata": {},
   "source": [
    "### 操作1 ストップワードの改良\n",
    "`stop_words.txt`を直接書き換えても良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 追加のストップワードを設定\n",
    "additionel_stopwords = []\n",
    "\n",
    "# ストップワードの読み込み\n",
    "with open(\"stop_words.txt\", encoding=\"utf-8\") as f:\n",
    "    stop_words = set(line.strip().lower() for line in f if line.strip())\n",
    "\n",
    "# ストップワードを追加\n",
    "stop_words.update(map(str.lower, additionel_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ffd92d",
   "metadata": {},
   "source": [
    "### 操作2 同じ意味を持つ単語の統合\n",
    "\"バスケ\", \"サッカー\", \"野球\"をすべて\"スポーツ\"に書き換えるという使い方も可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 意味の同じ単語を1語にまとめるための変換辞書\n",
    "replace_dict = {\n",
    "    \n",
    "}\n",
    "\n",
    "# 統合関数により単語の並びを変えることなく目的語を変換出来る\n",
    "def batch_replace(sentences, replace_dict):\n",
    "    return [\n",
    "        [replace_dict.get(token, token) for token in sentence]\n",
    "        for sentence in sentences\n",
    "    ]\n",
    "\n",
    "\n",
    "# トークン化\n",
    "sentences = df[\"text\"].apply(tokenize_clean)\n",
    "# 変換辞書を適用\n",
    "sentences = batch_replace(sentences, replace_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c12ca",
   "metadata": {},
   "source": [
    "### 操作3 Word2Vecの作成\n",
    "パラメータを自分で設定してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"モデルの語彙数：{len(model.wv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29acb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下のコードで語彙に含まれるすべての単語を確認できる\n",
    "# model.wv.index_to_key[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1283d0e",
   "metadata": {},
   "source": [
    "### 操作4 今日学んだ内容を振り返り，分析してください\n",
    "セルはいくらでも追加してください．<br>\n",
    "右上の`+`を押せばセルが追加されます．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4929e",
   "metadata": {},
   "source": [
    "### 考察問題2 以下の内容で考察してください\n",
    "社会人講座第3回で作成したシナリオから分散表現を獲得し，スケジュール管理における不便さやストレスを探り，ITツールを活用してより効率的かつ正確に予定を管理する方法を見つける．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd9c6ce",
   "metadata": {},
   "source": [
    "回答欄"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
